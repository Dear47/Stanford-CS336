#%%
import torch
import numpy as np
import numpy.typing as npt
import wandb
import pathlib
from tqdm import tqdm
from cs336_basics.utils.logger import get_logger
from cs336_basics.transformer.transformer_utils import *
from cs336_basics.transformer.module import *
logger = get_logger(__name__,'LM_trainer_v1.txt')
#%%
if __name__ == '__main__':
    model_config = {
        "vocab_size": 10000,      # è¯æ±‡è¡¨å¤§å°
        "context_length": 256,    #ä¸Šä¸‹æ–‡é•¿åº¦
        "num_layers": 4,          # TransformerBlockæ•°
        "num_heads": 16,          # æ³¨æ„åŠ›å¤´æ•°
        "d_model": 512,           # åµŒå…¥ç©ºé—´ç»´åº¦
        "d_ff": 1344,             # å‰é¦ˆç½‘ç»œç»´åº¦, 512 * 2.66 â‰ˆ 1366, é‡‡ç”¨æœ€æ¥è¿‘64æ•´æ•°å€çš„1344(æé«˜GPUåˆ©ç”¨ç‡)
        "theta": 10000,           # RoPEå‚æ•°
    }

    optim_config = {
        "lr": 3e-4,               # å­¦ä¹ ç‡
        "weight_decay": 1e-2,     # æƒé‡è¡°å‡
        "betas": (0.9, 0.999),    # betaå‚æ•°
        "max_l2_norm": 1.0,       # æ¢¯åº¦è£å‰ªçš„æœ€å¤§èŒƒæ•°
    }

    train_config = {
        "batch_size": 16,         # æ‰¹æ¬¡å¤§å°
        "total_epochs": 1,      # è®­ç»ƒè½®æ•°
        "checkpoint_freq": 2000,  # æ¯éš”å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
        "log_freq": 50,           # æ¯éš”å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
        "val_freq": 500,          # æ¯éš”å¤šå°‘æ­¥åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        "val_batch_size": 16,     # éªŒè¯æ—¶æ¯ä¸ªæ‰¹æ¬¡çš„å¤§å°
        "val_batches": 20,        # éªŒè¯æ—¶ä½¿ç”¨çš„æ‰¹æ¬¡æ•°é‡
    }

    PATH = pathlib.Path(__file__).resolve().parent.parent
    data_paths = {
        "training_dataset_path": PATH/"data/token/TinyStoriesV2-GPT4_train.npy",  # è®­ç»ƒé›†è·¯å¾„
        "validation_dataset_path": PATH/"data/token/TinyStoriesV2-GPT4_valid.npy",  # éªŒè¯é›†è·¯å¾„
        "checkpoint_load_path": None,  # æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        "checkpoint_save_format": PATH/"data/model/checkpoint_v1_{}.pt",  # æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„æ ¼å¼
        "final_model_path": PATH/"data/model/final_model_v1.pt",  # æœ€ç»ˆæ¨¡å‹ä¿å­˜è·¯å¾„
    }

    run = wandb.init(
        project="cs336-assignment-1",
        name="train_v1",
        config={
            "model": model_config,
            "optimizer": optim_config,
            "training": train_config,
        }
    )

    device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")

    logger.info("âš™ï¸ Initialize model...")
    model = TransformerLM(
        vocab_size=model_config['vocab_size'],
        context_length=model_config["context_length"],
        num_layers=model_config["num_layers"],
        d_model=model_config['d_model'],
        num_heads=model_config['num_heads'],
        d_ff=model_config["d_ff"],
        theta=model_config["theta"],
        device=device,
    )
    logger.info("âœ… Model initializtion has finished!")

    logger.info("âš™ï¸ Initialize optimizer...")
    optim = AdamW(
        params=model.parameters(),
        lr=optim_config["lr"],
        weight_decay=optim_config["weight_decay"],
        betas=optim_config["betas"],
    )
    logger.info("âœ… Optimizer initialization has finisded!")


    start_iter = 1
    if data_paths["checkpoint_load_path"]:
        logger.info(f"âš™ï¸ Load checkpoint:{data_paths['checkpoint_load_path']}...")
        start_iter = load_checkpoint(data_paths["checkpoint_load_path"], model=model, optimizer=optim)
        start_iter += 1
        logger.info(f"âœ… Load checkpoint successfully, current iteration:{start_iter}.")
    else:
        logger.info("ğŸ¤” No checkpoint, train the model from scratch!")

    logger.info(f"âš™ï¸ Loading training dataset:{data_paths['training_dataset_path']}...")
    training_dataset = np.memmap(data_paths["training_dataset_path"], mode='r',dtype=np.uint16)
    logger.info("âœ… Load training dataset successfully!")

    validation_dataset = None
    if data_paths["validation_dataset_path"]:
        logger.info(f"âš™ï¸ Loading validation dataset:{data_paths['validation_dataset_path']}...")
        validation_dataset = np.memmap(data_paths["validation_dataset_path"],mode='r',dtype=np.uint16)
        logger.info("âœ… Load validation dataset successfully!")
    
    total_tokens = training_dataset.shape[0]
    total_steps = int(train_config['total_epochs'] * total_tokens)//(train_config['batch_size']*model_config['context_length'])
    logger.info(f"Total tokens:{total_tokens}, train epochs:{train_config['total_epochs']}, batch size:{train_config['batch_size']}, context length:{model_config['context_length']}")
    logger.info(f"Total steps:{total_steps}")

    logger.info("ğŸ› ï¸ Start training the model...")
    for step in tqdm(range(start_iter, total_steps+1), desc="training", unit='step'):
        optim.zero_grad()

        lr = cosine_annealing_schedule(
            it=step,
            max_learning_rate=optim_config['lr'],
            min_learning_rate=optim_config["lr"]*0.01,
            warmup_iters=int(0.05 * total_steps),
            cosine_cycle_iters=int(0.95 * total_steps),
        )

        for group in optim.param_groups:
            group['lr'] = lr
        
        inputs, targets = get_batch(
            dataset=training_dataset,
            batch_size=train_config['batch_size'],
            context_length=model_config['context_length'],
            device=device   
        )

        logits = model(inputs)

        loss = cross_entropy(inputs=logits, targets=targets)

        loss.backward()

        gradient_clipping(parameters=model.parameters(),max_l2_norm=optim_config['max_l2_norm'])
        optim.step()

        if step % train_config["log_freq"] == 0:
            grad_norm = compute_grad_norm(model.parameters())
            logger.info(f"ğŸ¤– Step:{step}, Loss:{loss.item()}, Grad_l2_norm:{grad_norm}")
            run.log({"train_loss":loss.item(), "lr":lr, "grad_l2_norm":grad_norm, "step":step})
        
        if validation_dataset is not None and step % train_config["val_freq"] == 0:
            logger.info("ğŸ¯ Eval the model on validation dataset...")
            val_loss = evaluate_model(
                model=model,
                dataset=validation_dataset,
                batch_size=train_config['val_batch_size'],
                context_length=model_config["context_length"],
                num_batches=train_config["val_batches"],
                device=device
            )
            logger.info(f"ğŸ¤– Loss on validation dataset:{val_loss}")
            run.log({'val_loss':val_loss, 'step':step})

        if step % train_config["checkpoint_freq"]==0:
            checkpoint_save_path = str(data_paths["checkpoint_save_format"]).format(step)
            logger.info(f"âš™ï¸ Save the checkpoint to: {checkpoint_save_path}...")
            save_checkpoint(
                model=model,
                optimizer=optim,
                iteration=step,
                out=checkpoint_save_path
            )
            logger.info("âœ… Save the checkpoint successfully!")

    logger.info("âœ… Train the model successfully!")

    logger.info(f"âš™ï¸ Save the final model to:{data_paths['final_model_path']}...")
    save_checkpoint(
        model=model,
        optimizer=optim,
        iteration=step,
        out=data_paths["final_model_path"]
    )
    logger.info("âœ… Save the final model successfully!")

    run.finish()